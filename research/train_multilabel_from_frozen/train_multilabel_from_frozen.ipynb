{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f9c7f75-3d3a-4ec3-af16-e87bd2e8f08e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (3.0.4)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from xgboost) (1.15.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efb8adb9-53c4-4911-b4d4-fc93b6c1d3c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MLP training: 100%|██████████| 30/30 [00:05<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp mAP: 0.8987727452817657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XGB training: 100%|██████████| 26/26 [00:10<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb mAP: 0.8459730442030611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logisting training: 100%|██████████| 26/26 [01:36<00:00,  3.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lin mAP: 0.9089192378258985\n"
     ]
    }
   ],
   "source": [
    "# minimal, end-to-end training on weak multi-label data with masks\n",
    "# deps: pip install torch scikit-learn joblib numpy\n",
    "\n",
    "import os, json, math, random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import xgboost as xgb\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ------------------------------ data loading ------------------------------\n",
    "\n",
    "def _load_bucket_flat(bucket_dir, polarity):\n",
    "    \"\"\"load a flat bucket (positives/negatives) -> list of (emb, fname, label, polarity)\"\"\"\n",
    "    bucket_dir = Path(bucket_dir)\n",
    "    embs = joblib.load(bucket_dir / \"embeddings.joblib\")      # list/array of vectors\n",
    "    labels = json.loads((bucket_dir / \"labels.json\").read_text())     # list[str]\n",
    "    fnames = json.loads((bucket_dir / \"filenames.json\").read_text())  # list[str]\n",
    "    assert len(embs) == len(labels) == len(fnames), \"mismatched lengths in bucket\"\n",
    "    out = []\n",
    "    for emb, lab, fn in zip(embs, labels, fnames):\n",
    "        emb = np.asarray(emb, dtype=np.float32)\n",
    "        out.append((emb, fn, lab, polarity))\n",
    "    return out\n",
    "\n",
    "def scan_root(root, pos_dir_name='tp', neg_dir_name='fp'):\n",
    "    \"\"\"scan flat positives/negatives structure and return combined records and class list\"\"\"\n",
    "    root = Path(root)\n",
    "    pos = _load_bucket_flat(root / pos_dir_name, polarity=1.0) if (root / pos_dir_name).exists() else []\n",
    "    neg = _load_bucket_flat(root / neg_dir_name, polarity=0.0) if (root / neg_dir_name).exists() else []\n",
    "    records = pos + neg\n",
    "\n",
    "    # collect unique class names\n",
    "    class_names = sorted({lab for (_, _, lab, _) in records})\n",
    "    class_to_idx = {c: i for i, c in enumerate(class_names)}\n",
    "    return records, class_names, class_to_idx\n",
    "\n",
    "def build_multilabel_table(root):\n",
    "    \"\"\"\n",
    "    dedupe by filename and build X, Y with weak multi-label targets\n",
    "    y in {1, 0, -1}; -1 means unknown (masked)\n",
    "    positive wins on conflicts; negative only sets if currently unknown\n",
    "    \"\"\"\n",
    "    records, class_names, class_to_idx = scan_root(root)\n",
    "    C = len(class_names)\n",
    "    by_file = {}   # fname -> {'embedding': np.array, 'y': np.full(C, -1)}\n",
    "\n",
    "    emb_dim = None\n",
    "    for emb, fname, label, pol in records:\n",
    "        if emb_dim is None: emb_dim = int(emb.shape[-1])\n",
    "        ci = class_to_idx[label]\n",
    "        slot = by_file.get(fname)\n",
    "        if slot is None:\n",
    "            y = np.full(C, -1.0, dtype=np.float32)\n",
    "            y[ci] = float(pol)\n",
    "            by_file[fname] = {\"embedding\": emb.astype(np.float32), \"y\": y}\n",
    "        else:\n",
    "            cur = slot[\"y\"][ci]\n",
    "            if pol == 1.0:\n",
    "                slot[\"y\"][ci] = 1.0\n",
    "            elif cur == -1.0:\n",
    "                slot[\"y\"][ci] = 0.0\n",
    "\n",
    "    X, Y, F = [], [], []\n",
    "    for fname, rec in by_file.items():\n",
    "        X.append(rec[\"embedding\"])\n",
    "        Y.append(rec[\"y\"])\n",
    "        F.append(fname)\n",
    "    X = np.stack(X).astype(np.float32)\n",
    "    Y = np.stack(Y).astype(np.float32)\n",
    "    return X, Y, F, class_names, emb_dim\n",
    "\n",
    "\n",
    "# ------------------------------ dataset ------------------------------\n",
    "\n",
    "class WeakMultiLabelDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = torch.from_numpy(X)\n",
    "        self.Y = torch.from_numpy(Y)\n",
    "    def __len__(self): return self.X.shape[0]\n",
    "    def __getitem__(self, i): return self.X[i], self.Y[i]\n",
    "\n",
    "def split_indices(n, y, val_frac=0.2, test_frac=0.0, seed=0):\n",
    "    \"\"\"partition dataset based on class and label (pos or neg)\"\"\"\n",
    "    # create class+label label\n",
    "    tmp = np.array([str(i) + '_' + str(int(j)) for i, j in zip(y.argmax(axis=1), y.max(axis=1))])\n",
    "    val_size = int(val_frac * n)\n",
    "    test_size = int(test_frac * n)\n",
    "    if val_frac > 0:\n",
    "        idx_train, idx_val = train_test_split(\n",
    "            np.arange(n), \n",
    "            test_size=val_size, \n",
    "            stratify=tmp\n",
    "        )\n",
    "    else:\n",
    "        idx_val = []\n",
    "    if test_frac > 0:\n",
    "        idx_train, idx_test = train_test_split(\n",
    "            idx_train, \n",
    "            test_size=test_size, \n",
    "            stratify=tmp[idx_train]\n",
    "        )\n",
    "    else:\n",
    "        idx_test = []\n",
    "    return idx_train, idx_val, idx_test\n",
    "\n",
    "# ------------------------------ model ------------------------------\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, hidden=256, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LayerNorm(in_dim),\n",
    "            nn.Linear(in_dim, hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden, out_dim),\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)  # logits\n",
    "\n",
    "# ------------------------------ masked loss ------------------------------\n",
    "\n",
    "class MaskedBCEWithLogits(nn.Module):\n",
    "    def __init__(self, pos_weight=None, reduction='mean', mask_val=-1.0):\n",
    "        super().__init__()\n",
    "        self.bce = nn.BCEWithLogitsLoss(weight=None, pos_weight=pos_weight, reduction='none')\n",
    "        self.reduction = reduction\n",
    "        self.mask_val = mask_val\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        # targets in {1,0,-1}; mask unknowns\n",
    "        mask = (targets != self.mask_val).float()\n",
    "        # fill unknowns with 0 to avoid nan in BCE; they will be masked out\n",
    "        safe_targets = torch.where(mask.bool(), targets, torch.zeros_like(targets))\n",
    "        per_elem = self.bce(logits, safe_targets)\n",
    "        per_elem = per_elem * mask\n",
    "        # reduce over classes then over batch\n",
    "        # small epsilon to avoid div-by-zero if a batch has all-masked for a class\n",
    "        denom = mask.sum(dim=1).clamp_min(1.0)\n",
    "        per_sample = per_elem.sum(dim=1) / denom\n",
    "        if self.reduction == 'mean':\n",
    "            return per_sample.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return per_sample.sum()\n",
    "        else:\n",
    "            return per_sample\n",
    "\n",
    "# ------------------------------ metrics ------------------------------\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device, class_names):\n",
    "    model.eval()\n",
    "    all_logits, all_targets = [], []\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(device)\n",
    "        all_logits.append(model(xb).cpu())\n",
    "        all_targets.append(yb.cpu())\n",
    "    logits = torch.cat(all_logits, 0).numpy()\n",
    "    targets = torch.cat(all_targets, 0).numpy()  # [N, C], values in {1,0,-1}\n",
    "\n",
    "    per_class = {}\n",
    "    ap_list, auc_list = [], []\n",
    "    for ci, cname in enumerate(class_names):\n",
    "        mask = targets[:, ci] != -1.0\n",
    "        n_total = int(mask.sum())\n",
    "        n_pos = int((targets[mask, ci] == 1.0).sum())\n",
    "        n_neg = int((targets[mask, ci] == 0.0).sum())\n",
    "\n",
    "        if n_total < 2 or len(np.unique(targets[mask, ci])) < 2:\n",
    "            per_class[cname] = {\n",
    "                \"AP\": None,\n",
    "                \"AUROC\": None,\n",
    "                \"n_total\": n_total,\n",
    "                \"n_pos\": n_pos,\n",
    "                \"n_neg\": n_neg,\n",
    "            }\n",
    "            continue\n",
    "\n",
    "        y_true = targets[mask, ci]\n",
    "        y_score = logits[mask, ci]\n",
    "        try:\n",
    "            ap = float(average_precision_score(y_true, y_score))\n",
    "        except Exception:\n",
    "            ap = None\n",
    "        try:\n",
    "            auc = float(roc_auc_score(y_true, y_score))\n",
    "        except Exception:\n",
    "            auc = None\n",
    "\n",
    "        per_class[cname] = {\n",
    "            \"AP\": ap,\n",
    "            \"AUROC\": auc,\n",
    "            \"n_total\": n_total,\n",
    "            \"n_pos\": n_pos,\n",
    "            \"n_neg\": n_neg,\n",
    "        }\n",
    "        if ap is not None: ap_list.append(ap)\n",
    "        if auc is not None: auc_list.append(auc)\n",
    "\n",
    "    macro_ap = float(np.mean(ap_list)) if ap_list else None\n",
    "    macro_auc = float(np.mean(auc_list)) if auc_list else None\n",
    "    return {\"macro_AP\": macro_ap, \"macro_AUROC\": macro_auc, \"per_class\": per_class}\n",
    "\n",
    "# ------------------------------ training loop ------------------------------\n",
    "\n",
    "def compute_pos_weight(Y, mask_val=-1.0):\n",
    "    # pos_weight = (num_neg / num_pos) per class using only known labels\n",
    "    C = Y.shape[1]\n",
    "    pos_weight = np.zeros(C, dtype=np.float32)\n",
    "    for c in range(C):\n",
    "        known = Y[:, c] != mask_val\n",
    "        if known.sum() == 0:\n",
    "            pos_weight[c] = 1.0\n",
    "        else:\n",
    "            pos = (Y[known, c] == 1.0).sum()\n",
    "            neg = (Y[known, c] == 0.0).sum()\n",
    "            pos_weight[c] = float(neg / max(pos, 1))\n",
    "    return torch.tensor(pos_weight, dtype=torch.float32)\n",
    "\n",
    "def train_mlp(\n",
    "    X, Y, class_names, idx_train, idx_val=None, idx_test=None,\n",
    "    batch_size=128,\n",
    "    hidden=256,\n",
    "    dropout=0.1,\n",
    "    lr=3e-4,\n",
    "    epochs=30,\n",
    "    seed=0,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    verbose=0,\n",
    "):\n",
    "    \"\"\"\n",
    "    trains an mlp with masked bce and optional early stopping on val.\n",
    "    unknowns (-1) are ignored by the loss. returns dict(model=..., metrics={...}).\n",
    "    \"\"\"\n",
    "\n",
    "    rng = np.random.RandomState(seed)\n",
    "\n",
    "    # split matrices\n",
    "    Xtr, Ytr = X[idx_train], Y[idx_train]\n",
    "    Xva = Yva = None\n",
    "    Xte = Yte = None\n",
    "    if idx_val is not None and len(idx_val) > 0:\n",
    "        Xva, Yva = X[idx_val], Y[idx_val]\n",
    "    if idx_test is not None and len(idx_test) > 0:\n",
    "        Xte, Yte = X[idx_test], Y[idx_test]\n",
    "\n",
    "    emb_dim = X.shape[1]\n",
    "    C = Y.shape[1]\n",
    "\n",
    "    # build model + optimizer\n",
    "    pos_weight = compute_pos_weight(Ytr)  # tensor [C]\n",
    "    model = MLP(emb_dim, C, hidden=hidden, dropout=dropout).to(device)\n",
    "    criterion = MaskedBCEWithLogits(pos_weight=pos_weight.to(device))\n",
    "    optim = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    sched = torch.optim.lr_scheduler.CosineAnnealingLR(optim, T_max=max(epochs, 1))\n",
    "\n",
    "    # loaders\n",
    "    ds_tr = WeakMultiLabelDataset(Xtr, Ytr)\n",
    "    dl_tr = DataLoader(ds_tr, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "\n",
    "    if Xva is not None:\n",
    "        ds_va = WeakMultiLabelDataset(Xva, Yva)\n",
    "        dl_va = DataLoader(ds_va, batch_size=batch_size, shuffle=False)\n",
    "    else:\n",
    "        ds_va = dl_va = None\n",
    "\n",
    "    if Xte is not None:\n",
    "        ds_te = WeakMultiLabelDataset(Xte, Yte)\n",
    "        dl_te = DataLoader(ds_te, batch_size=batch_size, shuffle=False)\n",
    "    else:\n",
    "        ds_te = dl_te = None\n",
    "\n",
    "    # training loop with early stopping on val loss when available\n",
    "    best_va = math.inf\n",
    "    best_state = None\n",
    "\n",
    "    for ep in tqdm(range(1, epochs + 1), desc='MLP training'):\n",
    "        model.train()\n",
    "        running = 0.0\n",
    "        n_seen = 0\n",
    "        for xb, yb in dl_tr:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "            optim.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # clip helps with small/imbalanced data\n",
    "            optim.step()\n",
    "            running += loss.item() * xb.size(0)\n",
    "            n_seen += xb.size(0)\n",
    "        sched.step()\n",
    "        tr_loss = running / max(n_seen, 1)\n",
    "\n",
    "        if dl_va is not None:\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                va_loss = 0.0\n",
    "                n_va = 0\n",
    "                for xb, yb in dl_va:\n",
    "                    xb = xb.to(device)\n",
    "                    yb = yb.to(device)\n",
    "                    va_loss += criterion(model(xb), yb).item() * xb.size(0)\n",
    "                    n_va += xb.size(0)\n",
    "                va_loss /= max(n_va, 1)\n",
    "\n",
    "            if va_loss < best_va:\n",
    "                best_va = va_loss\n",
    "                best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"epoch {ep:02d} | train_loss {tr_loss:.4f} | val_loss {va_loss:.4f}\")\n",
    "        elif verbose:\n",
    "            print(f\"epoch {ep:02d} | train_loss {tr_loss:.4f}\")\n",
    "\n",
    "    # restore best val checkpoint if we had a val split\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    # metrics: prefer test if provided; also report val if provided\n",
    "    metrics = {}\n",
    "    if dl_va is not None:\n",
    "        metrics[\"val\"] = evaluate(model, dl_va, device, class_names)\n",
    "    if dl_te is not None:\n",
    "        metrics[\"test\"] = evaluate(model, dl_te, device, class_names)\n",
    "    if not metrics:\n",
    "        # if neither val nor test given, evaluate on train just so caller gets something\n",
    "        dl_tmp = DataLoader(ds_tr, batch_size=batch_size, shuffle=False)\n",
    "        metrics[\"train\"] = evaluate(model, dl_tmp, device, class_names)\n",
    "\n",
    "    return {\"model\": model, \"metrics\": metrics}\n",
    "\n",
    "\n",
    "# ------------------------- helpers -------------------------\n",
    "\n",
    "def _eval_split(scores, y_true):\n",
    "    # compute AP/AUROC per class using only known labels\n",
    "    C = y_true.shape[1]\n",
    "    per_class = {}\n",
    "    ap_list, auc_list = [], []\n",
    "    for ci in range(C):\n",
    "        mask = y_true[:, ci] != -1.0\n",
    "        if mask.sum() < 2 or len(np.unique(y_true[mask, ci])) < 2:\n",
    "            per_class[ci] = {\n",
    "                \"AP\": None,\n",
    "                \"AUROC\": None,\n",
    "                \"n_pos\": int((y_true[mask, ci] == 1.0).sum()),\n",
    "                \"n_neg\": int((y_true[mask, ci] == 0.0).sum()),\n",
    "            }\n",
    "            continue\n",
    "        y = y_true[mask, ci]\n",
    "        s = scores[mask, ci]\n",
    "        ap = average_precision_score(y, s)\n",
    "        auc = roc_auc_score(y, s)\n",
    "        per_class[ci] = {\n",
    "            \"AP\": float(ap),\n",
    "            \"AUROC\": float(auc),\n",
    "            \"n_pos\": int((y == 1.0).sum()),\n",
    "            \"n_neg\": int((y == 0.0).sum()),\n",
    "        }\n",
    "        ap_list.append(ap); auc_list.append(auc)\n",
    "    macro_ap = float(np.mean(ap_list)) if ap_list else None\n",
    "    macro_auc = float(np.mean(auc_list)) if auc_list else None\n",
    "    return {\"macro_AP\": macro_ap, \"macro_AUROC\": macro_auc, \"per_class\": per_class}\n",
    "\n",
    "\n",
    "# ------------------------- logistic regression -------------------------\n",
    "\n",
    "def train_linear(X, Y, class_names, idx_train, idx_val=None, idx_test=None, Cs=(0.1, 0.3, 1.0, 3.0, 10.0)):\n",
    "    \"\"\"\n",
    "    trains per-class logistic regression with simple C selection on val.\n",
    "    unknowns (-1) are ignored per class per split.\n",
    "    returns dict(models=..., metrics={'val':..., 'test':...})\n",
    "    \"\"\"\n",
    "    C_list = list(Cs)\n",
    "    C_default = C_list[len(C_list)//2]\n",
    "\n",
    "    models = [None] * len(class_names)\n",
    "\n",
    "    # fit per class with val-based C if provided\n",
    "    for ci, _ in tqdm(enumerate(class_names), total=len(class_names), desc='Logisting training'):\n",
    "        # build train set for this class\n",
    "        m_tr = Y[idx_train, ci] != -1.0\n",
    "        Xtr = X[idx_train][m_tr]; ytr = Y[idx_train, ci][m_tr]\n",
    "        if len(np.unique(ytr)) < 2:\n",
    "            # not enough label diversity\n",
    "            models[ci] = None\n",
    "            continue\n",
    "\n",
    "        # choose C using val AP (fallback to default if no val or degenerate)\n",
    "        best_C = C_default\n",
    "        if idx_val is not None and len(idx_val) > 0:\n",
    "            best_ap, best_C = -1.0, C_default\n",
    "            m_va_all = Y[idx_val, ci] != -1.0\n",
    "            if m_va_all.any() and len(np.unique(Y[idx_val, ci][m_va_all])) > 1:\n",
    "                for C in C_list:\n",
    "                    clf = LogisticRegression(\n",
    "                        penalty=\"l2\", C=C, max_iter=2000, solver=\"saga\", class_weight=\"balanced\"\n",
    "                    )\n",
    "                    clf.fit(Xtr, ytr)\n",
    "                    m_va = m_va_all\n",
    "                    s = clf.predict_proba(X[idx_val][m_va])[:, 1]\n",
    "                    ap = average_precision_score(Y[idx_val, ci][m_va], s)\n",
    "                    if ap > best_ap:\n",
    "                        best_ap, best_C = ap, C\n",
    "\n",
    "        # fit final model with chosen C on train\n",
    "        clf = LogisticRegression(\n",
    "            penalty=\"l2\", C=best_C, max_iter=2000, solver=\"saga\", class_weight=\"balanced\"\n",
    "        )\n",
    "        clf.fit(Xtr, ytr)\n",
    "        models[ci] = clf\n",
    "\n",
    "    # scores on val/test\n",
    "    metrics = {}\n",
    "    if idx_val is not None and len(idx_val) > 0:\n",
    "        S_val = np.zeros((len(idx_val), len(class_names)), dtype=np.float32)\n",
    "        for ci, clf in enumerate(models):\n",
    "            if clf is None:\n",
    "                S_val[:, ci] = np.nan\n",
    "                continue\n",
    "            m_va = Y[idx_val, ci] != -1.0\n",
    "            S_val[m_va, ci] = clf.predict_proba(X[idx_val][m_va])[:, 1]\n",
    "        metrics[\"val\"] = _eval_split(S_val, Y[idx_val])\n",
    "\n",
    "    if idx_test is not None and len(idx_test) > 0:\n",
    "        S_te = np.zeros((len(idx_test), len(class_names)), dtype=np.float32)\n",
    "        for ci, clf in enumerate(models):\n",
    "            if clf is None:\n",
    "                S_te[:, ci] = np.nan\n",
    "                continue\n",
    "            m_te = Y[idx_test, ci] != -1.0\n",
    "            S_te[m_te, ci] = clf.predict_proba(X[idx_test][m_te])[:, 1]\n",
    "        metrics[\"test\"] = _eval_split(S_te, Y[idx_test])\n",
    "\n",
    "    return {\"models\": models, \"metrics\": metrics}\n",
    "\n",
    "# ------------------------- xgboost -------------------------\n",
    "\n",
    "def train_xgb(\n",
    "    X, Y, class_names, idx_train, idx_val=None, idx_test=None,\n",
    "    param_grid=(\n",
    "        {\"max_depth\": 3, \"min_child_weight\": 1},\n",
    "        {\"max_depth\": 4, \"min_child_weight\": 2},\n",
    "        {\"max_depth\": 5, \"min_child_weight\": 3},\n",
    "    ),\n",
    "    base_params=None,\n",
    "    num_boost_round=200,\n",
    "    early_stopping_rounds=30\n",
    "):\n",
    "    \"\"\"\n",
    "    trains per-class xgboost with light val tuning + early stopping.\n",
    "    unknowns (-1) are ignored per class per split.\n",
    "    returns dict(models=..., metrics={'val':..., 'test':...})\n",
    "    \"\"\"\n",
    "    if base_params is None:\n",
    "        base_params = {\n",
    "            \"objective\": \"binary:logistic\",\n",
    "            \"eval_metric\": \"auc\",\n",
    "            \"tree_method\": \"hist\",\n",
    "            \"subsample\": 0.8,\n",
    "            \"colsample_bytree\": 0.8,\n",
    "            \"lambda\": 1.0,\n",
    "        }\n",
    "\n",
    "    models = [None] * len(class_names)\n",
    "    best_iters = [None] * len(class_names)\n",
    "\n",
    "    for ci, _ in tqdm(enumerate(class_names), total=len(class_names), desc='XGB training'):\n",
    "        m_tr = Y[idx_train, ci] != -1.0\n",
    "        Xtr = X[idx_train][m_tr]; ytr = Y[idx_train, ci][m_tr]\n",
    "        if len(np.unique(ytr)) < 2:\n",
    "            models[ci] = None\n",
    "            continue\n",
    "\n",
    "        dtr = xgb.DMatrix(Xtr, label=ytr)\n",
    "\n",
    "        # if val exists for this class, pick params by val AP with early stopping\n",
    "        chosen_params = dict(base_params)\n",
    "        chosen_n = num_boost_round\n",
    "        if idx_val is not None and len(idx_val) > 0:\n",
    "            m_va = Y[idx_val, ci] != -1.0\n",
    "            has_val = m_va.any() and len(np.unique(Y[idx_val, ci][m_va])) > 1\n",
    "            if has_val:\n",
    "                Xva = X[idx_val][m_va]; yva = Y[idx_val, ci][m_va]\n",
    "                dva = xgb.DMatrix(Xva, label=yva)\n",
    "                best_ap, best_combo = -1.0, None\n",
    "                for combo in param_grid:\n",
    "                    params = dict(base_params, **combo)\n",
    "                    bst = xgb.train(\n",
    "                        params, dtr,\n",
    "                        num_boost_round=num_boost_round,\n",
    "                        evals=[(dtr, \"train\"), (dva, \"val\")],\n",
    "                        early_stopping_rounds=early_stopping_rounds,\n",
    "                        verbose_eval=False,\n",
    "                    )\n",
    "                    # use val AP (more aligned with retrieval) instead of built-in auc\n",
    "                    y_score = bst.predict(dva, iteration_range=(0, bst.best_iteration+1))\n",
    "                    ap = average_precision_score(yva, y_score)\n",
    "                    if ap > best_ap:\n",
    "                        best_ap, best_combo = ap, (params, bst.best_iteration+1)\n",
    "                if best_combo is not None:\n",
    "                    chosen_params, chosen_n = best_combo\n",
    "\n",
    "        # train final model on train with chosen settings\n",
    "        bst_final = xgb.train(\n",
    "            chosen_params, dtr, num_boost_round=chosen_n, verbose_eval=False\n",
    "        )\n",
    "        models[ci] = bst_final\n",
    "        best_iters[ci] = chosen_n\n",
    "\n",
    "    # scores on val/test\n",
    "    metrics = {}\n",
    "    if idx_val is not None and len(idx_val) > 0:\n",
    "        S_val = np.zeros((len(idx_val), len(class_names)), dtype=np.float32)\n",
    "        for ci, bst in enumerate(models):\n",
    "            if bst is None:\n",
    "                S_val[:, ci] = np.nan\n",
    "                continue\n",
    "            m_va = Y[idx_val, ci] != -1.0\n",
    "            if m_va.any():\n",
    "                dva = xgb.DMatrix(X[idx_val][m_va])\n",
    "                S_val[m_va, ci] = bst.predict(dva)\n",
    "        metrics[\"val\"] = _eval_split(S_val, Y[idx_val])\n",
    "\n",
    "    if idx_test is not None and len(idx_test) > 0:\n",
    "        S_te = np.zeros((len(idx_test), len(class_names)), dtype=np.float32)\n",
    "        for ci, bst in enumerate(models):\n",
    "            if bst is None:\n",
    "                S_te[:, ci] = np.nan\n",
    "                continue\n",
    "            m_te = Y[idx_test, ci] != -1.0\n",
    "            if m_te.any():\n",
    "                dte = xgb.DMatrix(X[idx_test][m_te])\n",
    "                S_te[m_te, ci] = bst.predict(dte)\n",
    "        metrics[\"test\"] = _eval_split(S_te, Y[idx_test])\n",
    "\n",
    "    return {\"models\": models, \"metrics\": metrics}\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # dataset root path\n",
    "    ROOT = \"/home/ec2-user/SageMaker/projects/experimental/bio-ae-eval/artifacts/embeddings/20250811-075752/perch_bird/\"\n",
    "\n",
    "    # prepare data\n",
    "    X, Y, F, class_names, emb_dim = build_multilabel_table(ROOT)\n",
    "    n = X.shape[0]\n",
    "    tr_idx, va_idx, te_idx = split_indices(n, Y, val_frac=0.25, test_frac=0.25, seed=13)\n",
    "    \n",
    "    # train and compare models\n",
    "    results = train_mlp(X, Y, class_names, tr_idx, va_idx, te_idx)\n",
    "    print(f\"mlp mAP: {results['metrics']['test']['macro_AP']}\")\n",
    "    results = train_xgb(X, Y, class_names, tr_idx, va_idx, te_idx)\n",
    "    print(f\"xgb mAP: {results['metrics']['test']['macro_AP']}\")\n",
    "    results = train_linear(X, Y, class_names, tr_idx, va_idx, te_idx)\n",
    "    print(f\"lin mAP: {results['metrics']['test']['macro_AP']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a12a8f9b-9408-4757-9683-ff9118befcf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def count_pos_neg(Y: np.ndarray, class_names):\n",
    "#     # count positives (1) per column\n",
    "#     pos = np.sum(Y == 1, axis=0)\n",
    "#     # count negatives (0) per column\n",
    "#     neg = np.sum(Y == 0, axis=0)\n",
    "#     return pd.DataFrame({'class': class_names, 'npos': pos, 'nneg': neg})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ddca15-8d14-4c47-a338-ff9659622ed7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b00c8e-2f29-4cb6-a25d-40df54dfefd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
